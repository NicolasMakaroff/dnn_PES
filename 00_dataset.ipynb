{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "\n",
    "> Module allowing the creation of the dataset and data statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to illustrate the function define we will use the Ishigami function define as :\n",
    "\n",
    "$$\\begin{array}{ccccc}\n",
    "f & : & [-\\pi,\\pi]^3 & \\to & \\mathbb{R} \\\\\n",
    " & & (x_1,x_2,x_3) & \\mapsto & \\sin(x_1) + a\\times\\sin(x_2) + b\\times x_3^4\\times\\sin(x_1) \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "where $a = 7$ and $b = 0.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a database for this function using a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a_, b_ = 7, 0.1\n",
    "min_ = -np.pi*100\n",
    "max_ = np.pi*100\n",
    "data = np.random.randint(low=min_, high=max_, size=(100,3))/100\n",
    "output = np.sin(data[:,0]) + a_*np.sin(data[:,1]) + b_*np.power(data[:,2],4)*np.sin(data[:,0])\n",
    "value_ = {'x1':data[:,0], 'x2':data[:,1], 'x3':data[:,2],'y':output}\n",
    "database = pd.DataFrame(value_)\n",
    "database.to_csv('data/ishigami.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def open_data(file,\n",
    "              info = False):\n",
    "    \"\"\" Open the data and transform it in a DataFrame \n",
    "        Arguments :\n",
    "            :file: CSV to read and convert into a pandas DataFrame\n",
    "            :info: default = False : Boolean to get summary information on the created object\n",
    "        Output :\n",
    "            A pandas DataFrame with all the data from the CSV file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "    if info is True :\n",
    "        print('Five first rows of the generated DataFrame : \\n {}'.format(df.head()))\n",
    "        print('\\nDataFrame shape : {}\\n'.format(df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a usefull function charging a file and returning a dataframe version. `info` set to *True* will allow to print some statistics on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five first rows of the generated DataFrame : \n",
      "      x1    x2    x3         y\n",
      "0 -3.06  1.66 -0.46  6.890301\n",
      "1  2.19 -2.24  0.73 -4.652745\n",
      "2 -1.22  1.19  1.95  4.201639\n",
      "3 -2.08  1.69 -1.11  5.944645\n",
      "4  1.89 -2.14  2.72  0.250308\n",
      "\n",
      "DataFrame shape : (100, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "database = open_data('data/ishigami.csv',info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_train_test_set(dataframe,\n",
    "                          train_frac,\n",
    "                          test_frac,\n",
    "                          target,\n",
    "                          random_state = 123):\n",
    "    \"\"\" Create the train and test set for the training with a random method\n",
    "        Arguments :\n",
    "            :dataframe: pandas DataFrame containing the date to split\n",
    "            :train_frac: float, fraction number of training data to keep\n",
    "            :test_frac: float, fraction number of test data to keep\n",
    "            :target: string, name of the target value\n",
    "        Outputs : \n",
    "            :train_features: pandas DataFrame of the training points selected randomly\n",
    "            :train_labels: pandas DataFrame, outputs for the training\n",
    "            :test_features: pandas DataFrame of the test points selected randomly\n",
    "            :test_labels: pandas DataFrame, outputs for the tests\n",
    "    \"\"\"\n",
    "    train_dataset = dataframe.sample(frac = train_frac, random_state = random_state)\n",
    "    tmp = dataframe.drop(train_dataset.index)\n",
    "    test_dataset = tmp.sample(frac = test_frac, random_state = random_state)\n",
    "    tmp.drop(test_dataset.index)\n",
    "    train_labels = train_dataset.pop(target)\n",
    "    train_features = train_dataset\n",
    "    test_labels = test_dataset.pop(target)\n",
    "    test_features =test_dataset\n",
    "    return train_features, train_labels, test_features, test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn this database into a training set and a test set using `create_train_test_set`function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features, test_labels = create_train_test_set(database,0.8,1.,'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get insight on the data\n",
    "\n",
    "We can now check some statistics on the train set using get_statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_statistics(dataframe,\n",
    "                   *argv):\n",
    "    \"\"\" Compute some basic statistics over the data \n",
    "        Arguments :\n",
    "            :dataframe: pandas DataFrame \n",
    "            :*argv: allows to pass multiple DataFrame in one time\n",
    "        Output : None\n",
    "    \"\"\"\n",
    "    print('Statistics Computed : \\n {}'.format(dataframe.describe().transpose()))\n",
    "    for arg in argv :\n",
    "        print(arg.describe().transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics Computed : \n",
      "     count      mean       std   min     25%    50%     75%   max\n",
      "x1   80.0 -0.257250  1.615413 -3.12 -1.5725 -0.220  0.7350  2.96\n",
      "x2   80.0 -0.277500  1.806109 -3.04 -1.9900 -0.325  1.1450  3.11\n",
      "x3   80.0  0.146125  1.861266 -3.04 -1.4450  0.220  1.7125  3.12\n",
      "count    80.000000\n",
      "mean     -0.773725\n",
      "std       5.645724\n",
      "min     -15.798305\n",
      "25%      -5.385894\n",
      "50%      -0.858053\n",
      "75%       4.292206\n",
      "max      10.253852\n",
      "Name: y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_statistics(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "\n",
    "The two next function are here to shift and scale the data in two different ways :\n",
    "\n",
    "*  `norm`: substract the mean and divide by the standard deviation.\n",
    "*  `minmaxscaler`: substract the max and divide by $(\\max-\\min)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def norm(x):\n",
    "    \"\"\" Standardization of a dataset \n",
    "        Arguments :\n",
    "            :x: pandas Dataframe contening the data to standardize\n",
    "        Output :\n",
    "            A pandas DataFrame with standardize values\n",
    "    \"\"\"\n",
    "    x_stats = x.describe().transpose()\n",
    "    return((x - x_stats['mean'])/x_stats['std'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def minmaxscaler(x):\n",
    "    \"\"\" MinMax scale of a dataset \n",
    "        Arguments :\n",
    "            :x: pandas Dataframe contening the data to standardize\n",
    "        Output :\n",
    "            A pandas DataFrame with scaled values\n",
    "    \"\"\"\n",
    "    x_stats = x.describe().transpose()\n",
    "    return ((x-x_stats['max'])/(x_stats['max']-x_stats['min']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics Computed : \n",
      "     count          mean  std       min       25%       50%       75%       max\n",
      "x1   80.0  2.775558e-17  1.0 -1.772147 -0.814188  0.023059  0.614239  1.991596\n",
      "x2   80.0  5.551115e-18  1.0 -1.529531 -0.948171 -0.026300  0.787605  1.875579\n",
      "x3   80.0  2.220446e-17  1.0 -1.711806 -0.854862  0.039691  0.841564  1.597770\n"
     ]
    }
   ],
   "source": [
    "normed_train_features = norm(train_features)\n",
    "get_statistics(normed_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
